import xml.etree.ElementTree as ET
import os
from pyspark.sql.functions import col, lit, date_format, coalesce, current_timestamp
from common.setup.logger import get_logger

logger = get_logger("Processing")

def load_parser_rules(source_name, base_dir="/UEBA/common/parser/"):
    """ì¥ë¹„ëª…ê³¼ ë™ì¼í•œ ì´ë¦„ì˜ ë¶„ë¦¬ëœ XML íŒŒì¼ì„ ë™ì ìœ¼ë¡œ ì½ì–´ì˜µë‹ˆë‹¤."""
    xml_path = os.path.join(base_dir, f"{source_name}.xml")
    mappings = {}
    
    if not os.path.exists(xml_path):
        logger.warning(f"âš ï¸ XML íŒŒì„œ ì„¤ì • íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {xml_path}")
        return mappings
    
    try:
        tree = ET.parse(xml_path)
        root = tree.getroot()
        for field in root.iter('field'):
            target = field.get('target')
            source = field.get('source')
            if target and source:
                mappings[target] = source
    except Exception as e:
        logger.error(f"âŒ [{source_name}] XML íŒŒì‹± ì—ëŸ¬: {e}")
    return mappings

def normalize_data(spark, raw_pandas_df, source_name):
    try:
        raw_pandas_df = raw_pandas_df.astype(str).replace({'nan': '', 'None': '', 'NaT': ''})
    except: pass

    df = raw_pandas_df
    
    # ğŸ’¡ 1. XMLì—ì„œ ë™ì  ë§¤í•‘ ë£° ê°€ì ¸ì˜¤ê¸°
    mappings = load_parser_rules(source_name)
    mapped_count = 0
    
    # ğŸ’¡ 2. XML ë£°ì— ë”°ë¼ ì»¬ëŸ¼ ë§¤í•‘ (ì›ë³¸ì— source í•„ë“œê°€ ìˆìœ¼ë©´ target í•„ë“œë¡œ ë³µì‚¬)
    for target_col, source_col in mappings.items():
        if source_col in df.columns:
            df = df.withColumn(target_col, col(source_col))
            mapped_count += 1
            
    if mappings:
        logger.info(f"[{source_name}] ğŸ“œ XML íŒŒì„œ ì ìš© ì™„ë£Œ: {mapped_count}ê°œ í•„ë“œ ë§¤í•‘ë¨")

    # ğŸ’¡ 3. ì—”ì§„ì´ ìš”êµ¬í•˜ëŠ” UEBA í‘œì¤€ í•„ìˆ˜ í•„ë“œ ê»ë°ê¸° ë³´ì¥
    required_cols = ["user_id", "user", "department", "action", "src_ip", "log_source"]
    for c in required_cols:
        if c not in df.columns: 
            df = df.withColumn(c, lit(None).cast("string"))

    # ğŸ’¡ 4. ê²°ì¸¡ì¹˜(Null)ì— ëŒ€í•œ ìµœí›„ì˜ ê¸°ë³¸ê°’ ì„¤ì • (ì—ëŸ¬ ë°©ì§€ìš©)
    df = df.withColumn("user_id", coalesce(col("user_id"), lit("Unknown_ID")))
    df = df.withColumn("user", coalesce(col("user"), lit("Unknown_User")))
    df = df.withColumn("department", coalesce(col("department"), lit("Unknown_Dept")))
    df = df.withColumn("src_ip", coalesce(col("src_ip"), lit("Internal")))
    df = df.withColumn("action", coalesce(col("action"), lit("Unknown_Action")))
    df = df.withColumn("log_source", lit(source_name))

    # ğŸ’¡ 5. ì‹œê°„ í•„ë“œ ì²˜ë¦¬
    time_cols = []
    if "final_ts" in df.columns: time_cols.append(col("final_ts"))
    if "timestamp" in df.columns: time_cols.append(col("timestamp"))
    time_cols.append(current_timestamp())

    df = df.withColumn("final_ts", coalesce(*time_cols))
    df = df.withColumn("timestamp", date_format(col("final_ts"), "yyyy-MM-dd HH:mm:ss"))

    logger.info(f"[{source_name}] âœ¨ ë°ì´í„° ì •ì œ ì™„ë£Œ")
    return df